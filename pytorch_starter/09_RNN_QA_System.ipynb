{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "92JvvYftu_-c",
        "outputId": "5059e707-2536-4e69-ea04-a703189f41a9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchinfo import summary\n",
        "\n",
        "# to get deterministic output\n",
        "torch.manual_seed(123)\n",
        "\n",
        "sys.path.append(os.path.abspath(\"..\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Who directed the movie 'Titanic'?</td>\n",
              "      <td>JamesCameron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>Which superhero is also known as the Dark Knight?</td>\n",
              "      <td>Batman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>What is the capital of Brazil?</td>\n",
              "      <td>Brasilia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Which fruit is known as the king of fruits?</td>\n",
              "      <td>Mango</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Which country is known for the Eiffel Tower?</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question        answer\n",
              "0                      What is the capital of France?         Paris\n",
              "1                     What is the capital of Germany?        Berlin\n",
              "2                  Who wrote 'To Kill a Mockingbird'?    Harper-Lee\n",
              "3     What is the largest planet in our solar system?       Jupiter\n",
              "4      What is the boiling point of water in Celsius?           100\n",
              "..                                                ...           ...\n",
              "85                  Who directed the movie 'Titanic'?  JamesCameron\n",
              "86  Which superhero is also known as the Dark Knight?        Batman\n",
              "87                     What is the capital of Brazil?      Brasilia\n",
              "88        Which fruit is known as the king of fruits?         Mango\n",
              "89       Which country is known for the Eiffel Tower?        France\n",
              "\n",
              "[90 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../datasets/question_answer_dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NWdOVkZ1viJ3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  return text.split()\n",
        "\n",
        "tokenize('What is the capital of France?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XxpiMiXtw4oX"
      },
      "outputs": [],
      "source": [
        "vocab = {'<UNK>': 0}\n",
        "\n",
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_tokens:\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "9LSxaRRuxHlv",
        "outputId": "65f92b49-a082-466d-ac0e-e6470002bade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab size: 324\n"
          ]
        }
      ],
      "source": [
        "df.apply(build_vocab, axis=1)\n",
        "print(\"vocab size:\", len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BUBXvBNovvQa"
      },
      "outputs": [],
      "source": [
        "def text_to_indices(text, vocab):\n",
        "  indexed_text = []\n",
        "  for token in tokenize(text):\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "  return indexed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_to_indices(\"What is campusx\", vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PElUlPYT0gqK"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "InSZ-ZIm1Y1O"
      },
      "outputs": [],
      "source": [
        "dataset = MyDataset(df, vocab)\n",
        "train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the DataLoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40MDNe0v1iMN",
        "outputId": "088b17b8-dff4-456e-a3b4-ebbfcda65800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 0, torch.Size([1, 7]), torch.Size([1, 1])\n",
            "\t tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
            "batch: 1, torch.Size([1, 7]), torch.Size([1, 1])\n",
            "\t tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
            "batch: 2, torch.Size([1, 7]), torch.Size([1, 1])\n",
            "\t tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "batch: 3, torch.Size([1, 5]), torch.Size([1, 1])\n",
            "\t tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "batch: 4, torch.Size([1, 7]), torch.Size([1, 1])\n",
            "\t tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, (batch_x, batch_y) in enumerate(train_dataloader):\n",
        "  print(f\"batch: {batch_idx}, {batch_x.shape}, {batch_y.shape}\")\n",
        "  print(\"\\t\", batch_x, batch_y)\n",
        "  if batch_idx >= 4:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Design the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y2XLQyi6GN61"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedded = self.embedding(question)\n",
        "    internal_states, hidden_state = self.rnn(embedded)\n",
        "    logits = self.fc(hidden_state.squeeze(0))\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================================\n",
            "Layer (type:depth-idx)                   Kernel Shape     Input Shape      Output Shape     Param #\n",
            "========================================================================================================\n",
            "SimpleRNN                                --               [1, 7]           [1, 324]         --\n",
            "â”œâ”€Embedding: 1-1                         --               [1, 7]           [1, 7, 50]       16,200\n",
            "â”‚    â””â”€weight                            [50, 324]                                          â””â”€16,200\n",
            "â”œâ”€RNN: 1-2                               --               [1, 7, 50]       [1, 7, 64]       7,424\n",
            "â”‚    â””â”€weight_ih_l0                      [64, 50]                                           â”œâ”€3,200\n",
            "â”‚    â””â”€weight_hh_l0                      [64, 64]                                           â”œâ”€4,096\n",
            "â”‚    â””â”€bias_ih_l0                        [64]                                               â”œâ”€64\n",
            "â”‚    â””â”€bias_hh_l0                        [64]                                               â””â”€64\n",
            "â”œâ”€Linear: 1-3                            --               [1, 64]          [1, 324]         21,060\n",
            "â”‚    â””â”€weight                            [64, 324]                                          â”œâ”€20,736\n",
            "â”‚    â””â”€bias                              [324]                                              â””â”€324\n",
            "========================================================================================================\n",
            "Total params: 44,684\n",
            "Trainable params: 44,684\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 0.09\n",
            "========================================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.18\n",
            "Estimated Total Size (MB): 0.19\n",
            "========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = SimpleRNN(len(vocab))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "model_stats = summary(model, input_data=batch_x, verbose=2, col_width=16,\n",
        "                      col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyze The Model Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input sequence shape\t : torch.Size([1, 7])\n",
            "Embedding output shape\t : torch.Size([1, 7, 50])\n",
            "\n",
            "RNN internal states shape: torch.Size([1, 7, 64])\n",
            "RNN final state shape\t : torch.Size([1, 1, 64])\n",
            "\n",
            "FC layer output shape\t : torch.Size([1, 324])\n"
          ]
        }
      ],
      "source": [
        "emb_layer_output = model.embedding(batch_x)\n",
        "print(\"Input sequence shape\\t :\", batch_x.shape)\n",
        "print(\"Embedding output shape\\t :\", emb_layer_output.shape)\n",
        "\n",
        "internal_states, hidden_state = model.rnn(emb_layer_output)\n",
        "print(\"\\nRNN internal states shape:\", internal_states.shape)\n",
        "print(\"RNN final state shape\\t :\", hidden_state.shape)\n",
        "\n",
        "fc_layer_output = model.fc(hidden_state.squeeze(0))\n",
        "print(\"\\nFC layer output shape\\t :\", fc_layer_output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKITUSEnL-ol",
        "outputId": "5d57f8df-e6e2-4707-f1ba-ca79192ca786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/020 | epoch_loss: 531.15\n",
            "Epoch: 002/020 | epoch_loss: 459.17\n",
            "Epoch: 003/020 | epoch_loss: 380.93\n",
            "Epoch: 004/020 | epoch_loss: 322.42\n",
            "Epoch: 005/020 | epoch_loss: 272.64\n",
            "Epoch: 006/020 | epoch_loss: 225.88\n",
            "Epoch: 007/020 | epoch_loss: 182.12\n",
            "Epoch: 008/020 | epoch_loss: 143.38\n",
            "Epoch: 009/020 | epoch_loss: 110.73\n",
            "Epoch: 010/020 | epoch_loss: 85.50\n",
            "Epoch: 011/020 | epoch_loss: 66.07\n",
            "Epoch: 012/020 | epoch_loss: 51.40\n",
            "Epoch: 013/020 | epoch_loss: 40.57\n",
            "Epoch: 014/020 | epoch_loss: 32.63\n",
            "Epoch: 015/020 | epoch_loss: 26.63\n",
            "Epoch: 016/020 | epoch_loss: 22.01\n",
            "Epoch: 017/020 | epoch_loss: 18.40\n",
            "Epoch: 018/020 | epoch_loss: 15.65\n",
            "Epoch: 019/020 | epoch_loss: 13.40\n",
            "Epoch: 020/020 | epoch_loss: 11.64\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  model = model.train()  \n",
        "  for question, answer in train_dataloader:\n",
        "    # forward pass\n",
        "    logits = model(question)\n",
        "\n",
        "    # loss -> output shape (1,324) - (1)\n",
        "    loss = criterion(logits, answer[0])\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch+1:03d}/{epochs:03d} | epoch_loss: {epoch_loss:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fbZzQT07WIqj"
      },
      "outputs": [],
      "source": [
        "def predict(model, question, threshold=0.5):\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "  logits = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = nn.functional.softmax(logits, dim=1)\n",
        "  prob, index = torch.max(probs, dim=1)\n",
        "  if prob < threshold:\n",
        "    return \"I don't know\", prob.item()\n",
        "\n",
        "  return list(vocab.keys())[index], prob.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confidence: 0.86\n",
            "Answer: jupiter\n"
          ]
        }
      ],
      "source": [
        "prediction, confidence = predict(model, \"What is the largest planet in our solar system?\")\n",
        "print(f\"Confidence: {confidence:.2f}\")\n",
        "print(f\"Answer: {prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(model):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for _, datarow in df.iterrows():\n",
        "            prediction, prob = predict(model, datarow['question'])\n",
        "            correct += (prediction.casefold() == datarow['answer'].casefold())\n",
        "            total += 1\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "train_acc = calculate_accuracy(model)\n",
        "print(f\"Train Accuracy: {train_acc:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
