{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "92JvvYftu_-c",
        "outputId": "5059e707-2536-4e69-ea04-a703189f41a9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# to get deterministic output\n",
        "torch.manual_seed(123)\n",
        "\n",
        "sys.path.append(os.path.abspath(\"..\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Who directed the movie 'Titanic'?</td>\n",
              "      <td>JamesCameron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>Which superhero is also known as the Dark Knight?</td>\n",
              "      <td>Batman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>What is the capital of Brazil?</td>\n",
              "      <td>Brasilia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Which fruit is known as the king of fruits?</td>\n",
              "      <td>Mango</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Which country is known for the Eiffel Tower?</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question        answer\n",
              "0                      What is the capital of France?         Paris\n",
              "1                     What is the capital of Germany?        Berlin\n",
              "2                  Who wrote 'To Kill a Mockingbird'?    Harper-Lee\n",
              "3     What is the largest planet in our solar system?       Jupiter\n",
              "4      What is the boiling point of water in Celsius?           100\n",
              "..                                                ...           ...\n",
              "85                  Who directed the movie 'Titanic'?  JamesCameron\n",
              "86  Which superhero is also known as the Dark Knight?        Batman\n",
              "87                     What is the capital of Brazil?      Brasilia\n",
              "88        Which fruit is known as the king of fruits?         Mango\n",
              "89       Which country is known for the Eiffel Tower?        France\n",
              "\n",
              "[90 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../datasets/question_answer_dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NWdOVkZ1viJ3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  return text.split()\n",
        "\n",
        "tokenize('What is the capital of France?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XxpiMiXtw4oX"
      },
      "outputs": [],
      "source": [
        "vocab = {'<UNK>': 0}\n",
        "\n",
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_tokens:\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "9LSxaRRuxHlv",
        "outputId": "65f92b49-a082-466d-ac0e-e6470002bade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab size: 324\n"
          ]
        }
      ],
      "source": [
        "df.apply(build_vocab, axis=1)\n",
        "print(\"vocab size:\", len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BUBXvBNovvQa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def text_to_indices(text, vocab):\n",
        "  indexed_text = []\n",
        "  for token in tokenize(text):\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "  return indexed_text\n",
        "\n",
        "text_to_indices(\"What is campusx\", vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PElUlPYT0gqK"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "InSZ-ZIm1Y1O"
      },
      "outputs": [],
      "source": [
        "dataset = MyDataset(df, vocab)\n",
        "train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40MDNe0v1iMN",
        "outputId": "088b17b8-dff4-456e-a3b4-ebbfcda65800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n"
          ]
        }
      ],
      "source": [
        "for question, answer in train_dataloader:\n",
        "  print(question, answer)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Design the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y2XLQyi6GN61"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedded_question = self.embedding(question)\n",
        "    hidden, final = self.rnn(embedded_question)\n",
        "    logits = self.fc(final.squeeze(0))\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al9891aUW0e_",
        "outputId": "a9a5bf47-9723-4c73-a49c-439a13907d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_question\t\t: tensor([[1, 2, 3, 4, 5, 6]])\n",
            "input_question shape\t: torch.Size([1, 6])\n",
            "emb_output shape\t: torch.Size([1, 6, 50])\n",
            "rnn_hidden shape\t: torch.Size([1, 6, 64])\n",
            "rnn_final shape\t\t: torch.Size([1, 1, 64])\n",
            "fc_output shape\t\t: torch.Size([1, 324])\n"
          ]
        }
      ],
      "source": [
        "# Test the layers\n",
        "emb_layer = nn.Embedding(324, embedding_dim=50)\n",
        "rnn_layer = nn.RNN(50, 64, batch_first=True)\n",
        "fc_layer = nn.Linear(64, 324)\n",
        "\n",
        "input_question = dataset[0][0].reshape(1,-1)\n",
        "print(\"input_question\\t\\t:\", input_question)\n",
        "print(\"input_question shape\\t:\", input_question.shape)\n",
        "\n",
        "emb_layer_output = emb_layer(input_question)\n",
        "print(\"emb_output shape\\t:\", emb_layer_output.shape)\n",
        "\n",
        "rnn_hidden, rnn_final = rnn_layer(emb_layer_output)\n",
        "print(\"rnn_hidden shape\\t:\", rnn_hidden.shape)\n",
        "print(\"rnn_final shape\\t\\t:\", rnn_final.shape)\n",
        "\n",
        "fc_layer_output = fc_layer(rnn_final.squeeze(0))\n",
        "print(\"fc_output shape\\t\\t:\", fc_layer_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sk9pltE_KVgl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleRNN(\n",
              "  (embedding): Embedding(324, 50)\n",
              "  (rnn): RNN(50, 64, batch_first=True)\n",
              "  (fc): Linear(in_features=64, out_features=324, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = SimpleRNN(len(vocab))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKITUSEnL-ol",
        "outputId": "5d57f8df-e6e2-4707-f1ba-ca79192ca786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/020 | epoch_loss: 523.89\n",
            "Epoch: 002/020 | epoch_loss: 455.28\n",
            "Epoch: 003/020 | epoch_loss: 374.98\n",
            "Epoch: 004/020 | epoch_loss: 311.73\n",
            "Epoch: 005/020 | epoch_loss: 258.96\n",
            "Epoch: 006/020 | epoch_loss: 209.89\n",
            "Epoch: 007/020 | epoch_loss: 166.38\n",
            "Epoch: 008/020 | epoch_loss: 129.03\n",
            "Epoch: 009/020 | epoch_loss: 98.41\n",
            "Epoch: 010/020 | epoch_loss: 75.58\n",
            "Epoch: 011/020 | epoch_loss: 57.99\n",
            "Epoch: 012/020 | epoch_loss: 45.22\n",
            "Epoch: 013/020 | epoch_loss: 36.15\n",
            "Epoch: 014/020 | epoch_loss: 28.90\n",
            "Epoch: 015/020 | epoch_loss: 23.83\n",
            "Epoch: 016/020 | epoch_loss: 19.88\n",
            "Epoch: 017/020 | epoch_loss: 16.81\n",
            "Epoch: 018/020 | epoch_loss: 14.35\n",
            "Epoch: 019/020 | epoch_loss: 12.40\n",
            "Epoch: 020/020 | epoch_loss: 10.73\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  model = model.train()  \n",
        "  for question, answer in train_dataloader:\n",
        "    # forward pass\n",
        "    logits = model(question)\n",
        "\n",
        "    # loss -> output shape (1,324) - (1)\n",
        "    loss = criterion(logits, answer[0])\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch+1:03d}/{epochs:03d} | epoch_loss: {epoch_loss:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fbZzQT07WIqj"
      },
      "outputs": [],
      "source": [
        "def predict(model, question, threshold=0.5):\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "  logits = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = nn.functional.softmax(logits, dim=1)\n",
        "  prob, index = torch.max(probs, dim=1)\n",
        "  if prob < threshold:\n",
        "    return \"I don't know\", prob.item()\n",
        "\n",
        "  return list(vocab.keys())[index], prob.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confidence: 0.90\n",
            "Answer: jupiter\n"
          ]
        }
      ],
      "source": [
        "prediction, confidence = predict(model, \"What is the largest planet in our solar system?\")\n",
        "print(f\"Confidence: {confidence:.2f}\")\n",
        "print(f\"Answer: {prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(model):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for _, datarow in df.iterrows():\n",
        "            prediction, prob = predict(model, datarow['question'])\n",
        "            correct += (prediction.casefold() == datarow['answer'].casefold())\n",
        "            total += 1\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "train_acc = calculate_accuracy(model)\n",
        "print(f\"Train Accuracy: {train_acc:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
