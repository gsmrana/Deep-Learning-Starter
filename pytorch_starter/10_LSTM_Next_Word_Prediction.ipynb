{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ae7dunqczT8Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchinfo import summary\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# to get deterministic output\n",
        "torch.manual_seed(123)\n",
        "\n",
        "sys.path.append(os.path.abspath(\"..\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "document = \"\"\n",
        "with open(\"../datasets/word_prediction_dataset.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    document = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMU_RwfbzXt4",
        "outputId": "7fe012b9-4425-46b0-f109-e3174731f277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Nova\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Nova\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t28bgAcszaHl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Tokens: 1018\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['about',\n",
              " 'the',\n",
              " 'program',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'course',\n",
              " 'fee',\n",
              " 'for',\n",
              " 'data',\n",
              " 'science',\n",
              " 'mentorship',\n",
              " 'program',\n",
              " '(',\n",
              " 'dsmp',\n",
              " '2023',\n",
              " ')',\n",
              " 'the',\n",
              " 'course',\n",
              " 'follows']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_tokens = word_tokenize(document.lower())\n",
        "print(\"Total Tokens:\", len(all_tokens))\n",
        "all_tokens[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30GxEjgzcfY",
        "outputId": "63c6bf46-c4de-4126-8c12-5f574f70a545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab length: 289\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('<unk>', 0),\n",
              " ('about', 1),\n",
              " ('the', 2),\n",
              " ('program', 3),\n",
              " ('what', 4),\n",
              " ('is', 5),\n",
              " ('course', 6),\n",
              " ('fee', 7),\n",
              " ('for', 8),\n",
              " ('data', 9),\n",
              " ('science', 10),\n",
              " ('mentorship', 11),\n",
              " ('(', 12),\n",
              " ('dsmp', 13),\n",
              " ('2023', 14),\n",
              " (')', 15),\n",
              " ('follows', 16),\n",
              " ('a', 17),\n",
              " ('monthly', 18),\n",
              " ('subscription', 19)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = {'<unk>': 0}\n",
        "\n",
        "for token in Counter(all_tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "print(\"Vocab length:\", len(vocab))\n",
        "list(vocab.items())[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert Text to Numerical Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x52A3E1K1zjn"
      },
      "outputs": [],
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "  numerical_sentence = []\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "  return numerical_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eu66Zo3e1Wh9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence count: 78\n",
            "Numerical sequence count: 78\n"
          ]
        }
      ],
      "source": [
        "input_sentences = document.split('\\n')\n",
        "numerical_sequences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  tokens = word_tokenize(sentence.lower())\n",
        "  numerical_sequences.append(text_to_indices(tokens, vocab))\n",
        "\n",
        "print(\"Sentence count:\", len(input_sentences))\n",
        "print(\"Numerical sequence count:\", len(numerical_sequences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Training Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "80rIx4aq6ele"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training sequence count: 942\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[1, 2],\n",
              " [1, 2, 3],\n",
              " [4, 5],\n",
              " [4, 5, 2],\n",
              " [4, 5, 2, 6],\n",
              " [4, 5, 2, 6, 7],\n",
              " [4, 5, 2, 6, 7, 8],\n",
              " [4, 5, 2, 6, 7, 8, 9],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10, 11],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10, 11, 3],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10, 11, 3, 12],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10, 11, 3, 12, 13],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10, 11, 3, 12, 13, 14],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10, 11, 3, 12, 13, 14, 15],\n",
              " [2, 6],\n",
              " [2, 6, 16],\n",
              " [2, 6, 16, 17],\n",
              " [2, 6, 16, 17, 18],\n",
              " [2, 6, 16, 17, 18, 19]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_sequences = []\n",
        "for sequence in numerical_sequences:\n",
        "  for i in range(1, len(sequence)):\n",
        "    training_sequences.append(sequence[:i+1])\n",
        "    \n",
        "print(\"Training sequence count:\", len(training_sequences))\n",
        "training_sequences[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padding Training Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z_fiVZ8GRo",
        "outputId": "dc0971ee-ecb8-4061-c6aa-c5d751bb1da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sequence length: 62\n",
            "Padded Training Sequence length: 62\n"
          ]
        }
      ],
      "source": [
        "seq_lengths = []\n",
        "for sequence in training_sequences:\n",
        "  seq_lengths.append(len(sequence))\n",
        "\n",
        "max_seq_length = max(seq_lengths)\n",
        "print(\"Max sequence length:\", max_seq_length)\n",
        "\n",
        "padded_training_sequence = []\n",
        "for sequence in training_sequences:\n",
        "  padding_length = max_seq_length - len(sequence)\n",
        "  padded_training_sequence.append([0]*padding_length + sequence)\n",
        "  \n",
        "print(\"Padded Training Sequence length:\", len(padded_training_sequence[10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split the Features and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padded Training Sequence shape: torch.Size([942, 62])\n",
            "X shape: torch.Size([942, 61])\n",
            "y shape: torch.Size([942])\n"
          ]
        }
      ],
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)\n",
        "print(\"Padded Training Sequence shape:\", padded_training_sequence.shape)\n",
        "\n",
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ed_PLHJ-Dgv",
        "outputId": "7095458b-a2e8-4dc7-f150-80fd56d2c281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 285, 176],\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eReVrcX9-EUU",
        "outputId": "f2cca2e3-da31-4ef5-bc13-593203462048"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 2,  3,  5,  2,  6,  7,  8,  9, 10, 11])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X.to(device)\n",
        "    self.y = y.to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(X, y)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the DataLoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor([[  0,   0,   0,  ...,   5,   2, 254],\n",
            "        [  0,   0,   0,  ..., 185, 186,  78],\n",
            "        [  0,   0,   0,  ...,  65,  44, 163],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  85,  86,  87],\n",
            "        [  0,   0,   0,  ..., 225, 200, 223],\n",
            "        [  0,   0,   0,  ...,  30,  36,   2]], device='cuda:0') tensor([ 24, 187,  22,   2, 189,  53,  76,  93,  30, 206,  22,  36,  89,  15,\n",
            "          7,  52,  81,  33,  27,   8,  74, 252,  24,   2, 149,  65, 164, 117,\n",
            "         17,  17, 190,  31], device='cuda:0')\n",
            "1 tensor([[  0,   0,   0,  ...,   0,   0,  22],\n",
            "        [  0,   0,   0,  ...,   0, 213, 214],\n",
            "        [  0,   0,   0,  ..., 262, 252, 253],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  78,   4, 208],\n",
            "        [  0,   0,   0,  ...,  23,  24, 226],\n",
            "        [  0,   0,   0,  ..., 164, 165, 166]], device='cuda:0') tensor([ 23,  65,   5,  15, 128, 257,  27, 166,  17,  94, 268,  24, 135,   3,\n",
            "        110,  22,  80, 176,  94,  90,  30,  33,  78, 207,  15,  30,  28,  86,\n",
            "         12,  86,   2, 167], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for idx, (batch_x, batch_y) in enumerate(train_dataloader):\n",
        "  print(idx, batch_x, batch_y)\n",
        "  if idx >= 1:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Design the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    logits = self.fc(final_hidden_state.squeeze(0))\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_sequence shape\t: torch.Size([1, 61])\n",
            "embedding_output shape\t: torch.Size([1, 61, 100])\n",
            "lstm_hidden_states shape\t: torch.Size([1, 61, 150])\n",
            "lstm_final_hidden_state shape\t: torch.Size([1, 1, 150])\n",
            "lstm_final_cell_state shape\t: torch.Size([1, 1, 150])\n",
            "fully_connected_output shape\t: torch.Size([1, 289])\n"
          ]
        }
      ],
      "source": [
        "# Test the layers\n",
        "emb_layer = nn.Embedding(289, embedding_dim=100)\n",
        "lstm_layer = nn.LSTM(100, 150, batch_first=True)\n",
        "fc_layer = nn.Linear(150, 289)\n",
        "\n",
        "input_sequence = train_dataset[0][0].reshape(1,-1).to('cpu')\n",
        "print(\"input_sequence shape\\t:\", input_sequence.shape)\n",
        "\n",
        "emb_layer_output = emb_layer(input_sequence)\n",
        "print(\"embedding_output shape\\t:\", emb_layer_output.shape)\n",
        "\n",
        "hidden_states, (final_hidden_state, final_cell_state)= lstm_layer(emb_layer_output)\n",
        "print(\"lstm_hidden_states shape\\t:\", hidden_states.shape)\n",
        "print(\"lstm_final_hidden_state shape\\t:\", final_hidden_state.shape)\n",
        "print(\"lstm_final_cell_state shape\\t:\", final_cell_state.shape)\n",
        "\n",
        "fc_layer_output = fc_layer(final_hidden_state.squeeze(0))\n",
        "print(\"fully_connected_output shape\\t:\", fc_layer_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "LSTM                                     --\n",
              "├─Embedding: 1-1                         28,900\n",
              "├─LSTM: 1-2                              151,200\n",
              "├─Linear: 1-3                            43,639\n",
              "=================================================================\n",
              "Total params: 223,739\n",
              "Trainable params: 223,739\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = LSTM(len(vocab)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "7bc238c9-56d3-4558-db07-41d2474aa64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/050 | epoch_loss: 166.40\n",
            "Epoch: 002/050 | epoch_loss: 147.15\n",
            "Epoch: 003/050 | epoch_loss: 134.64\n",
            "Epoch: 004/050 | epoch_loss: 122.12\n",
            "Epoch: 005/050 | epoch_loss: 110.37\n",
            "Epoch: 006/050 | epoch_loss: 99.04\n",
            "Epoch: 007/050 | epoch_loss: 88.17\n",
            "Epoch: 008/050 | epoch_loss: 78.31\n",
            "Epoch: 009/050 | epoch_loss: 69.52\n",
            "Epoch: 010/050 | epoch_loss: 60.89\n",
            "Epoch: 011/050 | epoch_loss: 53.83\n",
            "Epoch: 012/050 | epoch_loss: 47.65\n",
            "Epoch: 013/050 | epoch_loss: 41.15\n",
            "Epoch: 014/050 | epoch_loss: 36.38\n",
            "Epoch: 015/050 | epoch_loss: 31.97\n",
            "Epoch: 016/050 | epoch_loss: 27.88\n",
            "Epoch: 017/050 | epoch_loss: 24.95\n",
            "Epoch: 018/050 | epoch_loss: 22.00\n",
            "Epoch: 019/050 | epoch_loss: 19.74\n",
            "Epoch: 020/050 | epoch_loss: 17.42\n",
            "Epoch: 021/050 | epoch_loss: 16.04\n",
            "Epoch: 022/050 | epoch_loss: 14.47\n",
            "Epoch: 023/050 | epoch_loss: 13.04\n",
            "Epoch: 024/050 | epoch_loss: 12.02\n",
            "Epoch: 025/050 | epoch_loss: 11.07\n",
            "Epoch: 026/050 | epoch_loss: 10.22\n",
            "Epoch: 027/050 | epoch_loss: 9.50\n",
            "Epoch: 028/050 | epoch_loss: 8.95\n",
            "Epoch: 029/050 | epoch_loss: 8.55\n",
            "Epoch: 030/050 | epoch_loss: 7.98\n",
            "Epoch: 031/050 | epoch_loss: 7.55\n",
            "Epoch: 032/050 | epoch_loss: 7.19\n",
            "Epoch: 033/050 | epoch_loss: 6.95\n",
            "Epoch: 034/050 | epoch_loss: 6.75\n",
            "Epoch: 035/050 | epoch_loss: 6.31\n",
            "Epoch: 036/050 | epoch_loss: 6.13\n",
            "Epoch: 037/050 | epoch_loss: 6.05\n",
            "Epoch: 038/050 | epoch_loss: 6.01\n",
            "Epoch: 039/050 | epoch_loss: 5.51\n",
            "Epoch: 040/050 | epoch_loss: 5.43\n",
            "Epoch: 041/050 | epoch_loss: 5.23\n",
            "Epoch: 042/050 | epoch_loss: 5.11\n",
            "Epoch: 043/050 | epoch_loss: 4.98\n",
            "Epoch: 044/050 | epoch_loss: 4.90\n",
            "Epoch: 045/050 | epoch_loss: 4.88\n",
            "Epoch: 046/050 | epoch_loss: 4.76\n",
            "Epoch: 047/050 | epoch_loss: 4.63\n",
            "Epoch: 048/050 | epoch_loss: 4.54\n",
            "Epoch: 049/050 | epoch_loss: 4.47\n",
            "Epoch: 050/050 | epoch_loss: 4.36\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  model = model.train()  \n",
        "  for batch_idx, (batch_x, batch_y) in enumerate(train_dataloader):\n",
        "    # forward pass\n",
        "    logits = model(batch_x)\n",
        "    loss = criterion(logits, batch_y)\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    # if not batch_idx % 8:\n",
        "    #   print(f' -> batch {batch_idx+1:03d} | loss: {loss:.2f}')\n",
        "  \n",
        "  print(f'Epoch: {epoch+1:03d}/{epochs:03d} | epoch_loss: {epoch_loss:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O9f6DkX-ZM-r"
      },
      "outputs": [],
      "source": [
        "def predict(model, vocab, input_text):\n",
        "  tokenized_text = word_tokenize(input_text.lower())\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "  padding_length = max_seq_length - 1 - len(numerical_text)\n",
        "  padded_text = torch.tensor([0]*padding_length + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "  logits = model(padded_text.to(device))\n",
        "  logit, index = torch.max(logits, dim=1)\n",
        "  return list(vocab.keys())[index], logit.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confidence: 9.85\n",
            "Answer: subscription\n"
          ]
        }
      ],
      "source": [
        "prediction, confidence = predict(model, vocab, \"The course follows a monthly\")\n",
        "print(f\"Confidence: {confidence:.2f}\")\n",
        "print(f\"Answer: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "0a36a6da-8118-4989-b754-e69826765f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The course follows a monthly subscription\n",
            "The course follows a monthly subscription model\n",
            "The course follows a monthly subscription model where\n",
            "The course follows a monthly subscription model where you\n",
            "The course follows a monthly subscription model where you have\n",
            "The course follows a monthly subscription model where you have to\n",
            "The course follows a monthly subscription model where you have to make\n",
            "The course follows a monthly subscription model where you have to make monthly\n",
            "The course follows a monthly subscription model where you have to make monthly payments\n",
            "The course follows a monthly subscription model where you have to make monthly payments of\n",
            "The course follows a monthly subscription model where you have to make monthly payments of rs\n",
            "The course follows a monthly subscription model where you have to make monthly payments of rs 799/month\n"
          ]
        }
      ],
      "source": [
        "num_tokens = 12\n",
        "input_prompt = \"The course follows a monthly\"\n",
        "\n",
        "for _ in range(num_tokens):\n",
        "  prediction, logit = predict(model, vocab, input_prompt)  \n",
        "  input_prompt += \" \" + prediction\n",
        "  print(input_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py7o0rJJc5pm",
        "outputId": "d6de41b2-e157-4da6-8dde-cd27de358a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(model, dataloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            probs = model(batch_x)\n",
        "            _, predicted = torch.max(probs, dim=1)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "test_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "accuracy = calculate_accuracy(model, test_dataloader)\n",
        "print(f\"Train Accuracy: {accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
