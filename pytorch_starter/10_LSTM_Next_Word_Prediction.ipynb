{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ae7dunqczT8Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# to get deterministic output\n",
        "torch.manual_seed(123)\n",
        "\n",
        "sys.path.append(os.path.abspath(\"..\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "document = \"\"\n",
        "with open(\"../datasets/word_prediction_dataset.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    document = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMU_RwfbzXt4",
        "outputId": "7fe012b9-4425-46b0-f109-e3174731f277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Nova\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Nova\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t28bgAcszaHl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token length: 1018\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['about',\n",
              " 'the',\n",
              " 'program',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'course',\n",
              " 'fee',\n",
              " 'for',\n",
              " 'data',\n",
              " 'science',\n",
              " 'mentorship',\n",
              " 'program',\n",
              " '(',\n",
              " 'dsmp',\n",
              " '2023',\n",
              " ')',\n",
              " 'the',\n",
              " 'course',\n",
              " 'follows',\n",
              " 'a',\n",
              " 'monthly',\n",
              " 'subscription',\n",
              " 'model',\n",
              " 'where',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'make',\n",
              " 'monthly',\n",
              " 'payments',\n",
              " 'of',\n",
              " 'rs',\n",
              " '799/month',\n",
              " '.',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'total',\n",
              " 'duration',\n",
              " 'of',\n",
              " 'the',\n",
              " 'course',\n",
              " '?',\n",
              " 'the',\n",
              " 'total',\n",
              " 'duration',\n",
              " 'of',\n",
              " 'the',\n",
              " 'course',\n",
              " 'is',\n",
              " '7',\n",
              " 'months',\n",
              " '.',\n",
              " 'so',\n",
              " 'the',\n",
              " 'total',\n",
              " 'course',\n",
              " 'fee',\n",
              " 'becomes',\n",
              " '799',\n",
              " '*',\n",
              " '7',\n",
              " '=',\n",
              " 'rs',\n",
              " '5600',\n",
              " '(',\n",
              " 'approx',\n",
              " '.',\n",
              " ')',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'syllabus',\n",
              " 'of',\n",
              " 'the',\n",
              " 'mentorship',\n",
              " 'program',\n",
              " '?',\n",
              " 'we',\n",
              " 'will',\n",
              " 'be',\n",
              " 'covering',\n",
              " 'the',\n",
              " 'following',\n",
              " 'modules',\n",
              " ':',\n",
              " 'python',\n",
              " 'fundamentals',\n",
              " 'python',\n",
              " 'libraries',\n",
              " 'for',\n",
              " 'data',\n",
              " 'science',\n",
              " 'data',\n",
              " 'analysis',\n",
              " 'sql',\n",
              " 'for',\n",
              " 'data',\n",
              " 'science',\n",
              " 'maths',\n",
              " 'for',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'ml',\n",
              " 'algorithms',\n",
              " 'practical',\n",
              " 'ml',\n",
              " 'mlops',\n",
              " 'case',\n",
              " 'studies',\n",
              " 'you',\n",
              " 'can',\n",
              " 'check',\n",
              " 'the',\n",
              " 'detailed',\n",
              " 'syllabus',\n",
              " 'here',\n",
              " '-',\n",
              " 'https',\n",
              " ':',\n",
              " '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390',\n",
              " 'will',\n",
              " 'deep',\n",
              " 'learning',\n",
              " 'and',\n",
              " 'nlp',\n",
              " 'be',\n",
              " 'a',\n",
              " 'part',\n",
              " 'of',\n",
              " 'this',\n",
              " 'program',\n",
              " '?',\n",
              " 'no',\n",
              " ',',\n",
              " 'nlp',\n",
              " 'and',\n",
              " 'deep',\n",
              " 'learning',\n",
              " 'both',\n",
              " 'are',\n",
              " 'not',\n",
              " 'a',\n",
              " 'part',\n",
              " 'of',\n",
              " 'this',\n",
              " 'program',\n",
              " 'â€™',\n",
              " 's',\n",
              " 'curriculum',\n",
              " '.',\n",
              " 'what',\n",
              " 'if',\n",
              " 'i',\n",
              " 'miss',\n",
              " 'a',\n",
              " 'live',\n",
              " 'session',\n",
              " '?',\n",
              " 'will',\n",
              " 'i',\n",
              " 'get',\n",
              " 'a',\n",
              " 'recording',\n",
              " 'of',\n",
              " 'the',\n",
              " 'session',\n",
              " '?',\n",
              " 'yes',\n",
              " 'all',\n",
              " 'our',\n",
              " 'sessions',\n",
              " 'are',\n",
              " 'recorded',\n",
              " ',',\n",
              " 'so',\n",
              " 'even',\n",
              " 'if',\n",
              " 'you',\n",
              " 'miss',\n",
              " 'a',\n",
              " 'session',\n",
              " 'you',\n",
              " 'can',\n",
              " 'go',\n",
              " 'back',\n",
              " 'and',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'recording',\n",
              " '.',\n",
              " 'where',\n",
              " 'can',\n",
              " 'i',\n",
              " 'find',\n",
              " 'the',\n",
              " 'class',\n",
              " 'schedule',\n",
              " '?',\n",
              " 'checkout',\n",
              " 'this',\n",
              " 'google',\n",
              " 'sheet',\n",
              " 'to',\n",
              " 'see',\n",
              " 'month',\n",
              " 'by',\n",
              " 'month',\n",
              " 'time',\n",
              " 'table',\n",
              " 'of',\n",
              " 'the',\n",
              " 'course',\n",
              " '-',\n",
              " 'https',\n",
              " ':',\n",
              " '//docs.google.com/spreadsheets/d/16ootax_a6oraecg4emgexhqqpv3noqpyku7rj6arozk/edit',\n",
              " '?',\n",
              " 'usp=sharing',\n",
              " '.',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'time',\n",
              " 'duration',\n",
              " 'of',\n",
              " 'all',\n",
              " 'the',\n",
              " 'live',\n",
              " 'sessions',\n",
              " '?',\n",
              " 'roughly',\n",
              " ',',\n",
              " 'all',\n",
              " 'the',\n",
              " 'sessions',\n",
              " 'last',\n",
              " '2',\n",
              " 'hours',\n",
              " '.',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'language',\n",
              " 'spoken',\n",
              " 'by',\n",
              " 'the',\n",
              " 'instructor',\n",
              " 'during',\n",
              " 'the',\n",
              " 'sessions',\n",
              " '?',\n",
              " 'hinglish',\n",
              " 'how',\n",
              " 'will',\n",
              " 'i',\n",
              " 'be',\n",
              " 'informed',\n",
              " 'about',\n",
              " 'the',\n",
              " 'upcoming',\n",
              " 'class',\n",
              " '?',\n",
              " 'you',\n",
              " 'will',\n",
              " 'get',\n",
              " 'a',\n",
              " 'mail',\n",
              " 'from',\n",
              " 'our',\n",
              " 'side',\n",
              " 'before',\n",
              " 'every',\n",
              " 'paid',\n",
              " 'session',\n",
              " 'once',\n",
              " 'you',\n",
              " 'become',\n",
              " 'a',\n",
              " 'paid',\n",
              " 'user',\n",
              " '.',\n",
              " 'can',\n",
              " 'i',\n",
              " 'do',\n",
              " 'this',\n",
              " 'course',\n",
              " 'if',\n",
              " 'i',\n",
              " 'am',\n",
              " 'from',\n",
              " 'a',\n",
              " 'non-tech',\n",
              " 'background',\n",
              " '?',\n",
              " 'yes',\n",
              " ',',\n",
              " 'absolutely',\n",
              " '.',\n",
              " 'i',\n",
              " 'am',\n",
              " 'late',\n",
              " ',',\n",
              " 'can',\n",
              " 'i',\n",
              " 'join',\n",
              " 'the',\n",
              " 'program',\n",
              " 'in',\n",
              " 'the',\n",
              " 'middle',\n",
              " '?',\n",
              " 'absolutely',\n",
              " ',',\n",
              " 'you',\n",
              " 'can',\n",
              " 'join',\n",
              " 'the',\n",
              " 'program',\n",
              " 'anytime',\n",
              " '.',\n",
              " 'if',\n",
              " 'i',\n",
              " 'join/pay',\n",
              " 'in',\n",
              " 'the',\n",
              " 'middle',\n",
              " ',',\n",
              " 'will',\n",
              " 'i',\n",
              " 'be',\n",
              " 'able',\n",
              " 'to',\n",
              " 'see',\n",
              " 'all',\n",
              " 'the',\n",
              " 'past',\n",
              " 'lectures',\n",
              " '?',\n",
              " 'yes',\n",
              " ',',\n",
              " 'once',\n",
              " 'you',\n",
              " 'make',\n",
              " 'the',\n",
              " 'payment',\n",
              " 'you',\n",
              " 'will',\n",
              " 'be',\n",
              " 'able',\n",
              " 'to',\n",
              " 'see',\n",
              " 'all',\n",
              " 'the',\n",
              " 'past',\n",
              " 'content',\n",
              " 'in',\n",
              " 'your',\n",
              " 'dashboard',\n",
              " '.',\n",
              " 'where',\n",
              " 'do',\n",
              " 'i',\n",
              " 'have',\n",
              " 'to',\n",
              " 'submit',\n",
              " 'the',\n",
              " 'task',\n",
              " '?',\n",
              " 'you',\n",
              " 'don',\n",
              " 'â€™',\n",
              " 't',\n",
              " 'have',\n",
              " 'to',\n",
              " 'submit',\n",
              " 'the',\n",
              " 'task',\n",
              " '.',\n",
              " 'we',\n",
              " 'will',\n",
              " 'provide',\n",
              " 'you',\n",
              " 'with',\n",
              " 'the',\n",
              " 'solutions',\n",
              " ',',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'self',\n",
              " 'evaluate',\n",
              " 'the',\n",
              " 'task',\n",
              " 'yourself',\n",
              " '.',\n",
              " 'will',\n",
              " 'we',\n",
              " 'do',\n",
              " 'case',\n",
              " 'studies',\n",
              " 'in',\n",
              " 'the',\n",
              " 'program',\n",
              " '?',\n",
              " 'yes',\n",
              " '.',\n",
              " 'where',\n",
              " 'can',\n",
              " 'we',\n",
              " 'contact',\n",
              " 'you',\n",
              " '?',\n",
              " 'you',\n",
              " 'can',\n",
              " 'mail',\n",
              " 'us',\n",
              " 'at',\n",
              " 'nitish.campusx',\n",
              " '@',\n",
              " 'gmail.com',\n",
              " 'payment/registration',\n",
              " 'related',\n",
              " 'questions',\n",
              " 'where',\n",
              " 'do',\n",
              " 'we',\n",
              " 'have',\n",
              " 'to',\n",
              " 'make',\n",
              " 'our',\n",
              " 'payments',\n",
              " '?',\n",
              " 'your',\n",
              " 'youtube',\n",
              " 'channel',\n",
              " 'or',\n",
              " 'website',\n",
              " '?',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'make',\n",
              " 'all',\n",
              " 'your',\n",
              " 'monthly',\n",
              " 'payments',\n",
              " 'on',\n",
              " 'our',\n",
              " 'website',\n",
              " '.',\n",
              " 'here',\n",
              " 'is',\n",
              " 'the',\n",
              " 'link',\n",
              " 'for',\n",
              " 'our',\n",
              " 'website',\n",
              " '-',\n",
              " 'https',\n",
              " ':',\n",
              " '//learnwith.campusx.in/',\n",
              " 'can',\n",
              " 'we',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'amount',\n",
              " 'of',\n",
              " 'rs',\n",
              " '5600',\n",
              " 'all',\n",
              " 'at',\n",
              " 'once',\n",
              " '?',\n",
              " 'unfortunately',\n",
              " 'no',\n",
              " ',',\n",
              " 'the',\n",
              " 'program',\n",
              " 'follows',\n",
              " 'a',\n",
              " 'monthly',\n",
              " 'subscription',\n",
              " 'model',\n",
              " '.',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'validity',\n",
              " 'of',\n",
              " 'monthly',\n",
              " 'subscription',\n",
              " '?',\n",
              " 'suppose',\n",
              " 'if',\n",
              " 'i',\n",
              " 'pay',\n",
              " 'on',\n",
              " '15th',\n",
              " 'jan',\n",
              " ',',\n",
              " 'then',\n",
              " 'do',\n",
              " 'i',\n",
              " 'have',\n",
              " 'to',\n",
              " 'pay',\n",
              " 'again',\n",
              " 'on',\n",
              " '1st',\n",
              " 'feb',\n",
              " 'or',\n",
              " '15th',\n",
              " 'feb',\n",
              " '15th',\n",
              " 'feb.',\n",
              " 'the',\n",
              " 'validity',\n",
              " 'period',\n",
              " 'is',\n",
              " '30',\n",
              " 'days',\n",
              " 'from',\n",
              " 'the',\n",
              " 'day',\n",
              " 'you',\n",
              " 'make',\n",
              " 'the',\n",
              " 'payment',\n",
              " '.',\n",
              " 'so',\n",
              " 'essentially',\n",
              " 'you',\n",
              " 'can',\n",
              " 'join',\n",
              " 'anytime',\n",
              " 'you',\n",
              " 'don',\n",
              " 'â€™',\n",
              " 't',\n",
              " 'have',\n",
              " 'to',\n",
              " 'wait',\n",
              " 'for',\n",
              " 'a',\n",
              " 'month',\n",
              " 'to',\n",
              " 'end',\n",
              " '.',\n",
              " 'what',\n",
              " 'if',\n",
              " 'i',\n",
              " 'don',\n",
              " 'â€™',\n",
              " 't',\n",
              " 'like',\n",
              " 'the',\n",
              " 'course',\n",
              " 'after',\n",
              " 'making',\n",
              " 'the',\n",
              " 'payment',\n",
              " '.',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'refund',\n",
              " 'policy',\n",
              " '?',\n",
              " 'you',\n",
              " 'get',\n",
              " 'a',\n",
              " '7',\n",
              " 'days',\n",
              " 'refund',\n",
              " 'period',\n",
              " 'from',\n",
              " 'the',\n",
              " 'day',\n",
              " 'you',\n",
              " 'have',\n",
              " 'made',\n",
              " 'the',\n",
              " 'payment',\n",
              " '.',\n",
              " 'i',\n",
              " 'am',\n",
              " 'living',\n",
              " 'outside',\n",
              " 'india',\n",
              " 'and',\n",
              " 'i',\n",
              " 'am',\n",
              " 'not',\n",
              " 'able',\n",
              " 'to',\n",
              " 'make',\n",
              " 'the',\n",
              " 'payment',\n",
              " 'on',\n",
              " 'the',\n",
              " 'website',\n",
              " ',',\n",
              " 'what',\n",
              " 'should',\n",
              " 'i',\n",
              " 'do',\n",
              " '?',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'contact',\n",
              " 'us',\n",
              " 'by',\n",
              " 'sending',\n",
              " 'a',\n",
              " 'mail',\n",
              " 'at',\n",
              " 'nitish.campusx',\n",
              " '@',\n",
              " 'gmail.com',\n",
              " 'post',\n",
              " 'registration',\n",
              " 'queries',\n",
              " 'till',\n",
              " 'when',\n",
              " 'can',\n",
              " 'i',\n",
              " 'view',\n",
              " 'the',\n",
              " 'paid',\n",
              " 'videos',\n",
              " 'on',\n",
              " 'the',\n",
              " 'website',\n",
              " '?',\n",
              " 'this',\n",
              " 'one',\n",
              " 'is',\n",
              " 'tricky',\n",
              " ',',\n",
              " 'so',\n",
              " 'read',\n",
              " 'carefully',\n",
              " '.',\n",
              " 'you',\n",
              " 'can',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'videos',\n",
              " 'till',\n",
              " 'your',\n",
              " 'subscription',\n",
              " 'is',\n",
              " 'valid',\n",
              " '.',\n",
              " 'suppose',\n",
              " 'you',\n",
              " 'have',\n",
              " 'purchased',\n",
              " 'subscription',\n",
              " 'on',\n",
              " '21st',\n",
              " 'jan',\n",
              " ',',\n",
              " 'you',\n",
              " 'will',\n",
              " 'be',\n",
              " 'able',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'all',\n",
              " 'the',\n",
              " 'past',\n",
              " 'paid',\n",
              " 'sessions',\n",
              " 'in',\n",
              " 'the',\n",
              " 'period',\n",
              " 'of',\n",
              " '21st',\n",
              " 'jan',\n",
              " 'to',\n",
              " '20th',\n",
              " 'feb.',\n",
              " 'but',\n",
              " 'after',\n",
              " '21st',\n",
              " 'feb',\n",
              " 'you',\n",
              " 'will',\n",
              " 'have',\n",
              " 'to',\n",
              " 'purchase',\n",
              " 'the',\n",
              " 'subscription',\n",
              " 'again',\n",
              " '.',\n",
              " 'but',\n",
              " 'once',\n",
              " 'the',\n",
              " 'course',\n",
              " 'is',\n",
              " 'over',\n",
              " 'and',\n",
              " 'you',\n",
              " 'have',\n",
              " 'paid',\n",
              " 'us',\n",
              " 'rs',\n",
              " '5600',\n",
              " '(',\n",
              " 'or',\n",
              " '7',\n",
              " 'installments',\n",
              " 'of',\n",
              " 'rs',\n",
              " '799',\n",
              " ')',\n",
              " 'you',\n",
              " 'will',\n",
              " 'be',\n",
              " 'able',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'paid',\n",
              " 'sessions',\n",
              " 'till',\n",
              " 'aug',\n",
              " '2024.',\n",
              " 'why',\n",
              " 'lifetime',\n",
              " 'validity',\n",
              " 'is',\n",
              " 'not',\n",
              " 'provided',\n",
              " '?',\n",
              " 'because',\n",
              " 'of',\n",
              " 'the',\n",
              " 'low',\n",
              " 'course',\n",
              " 'fee',\n",
              " '.',\n",
              " 'where',\n",
              " 'can',\n",
              " 'i',\n",
              " 'reach',\n",
              " 'out',\n",
              " 'in',\n",
              " 'case',\n",
              " 'of',\n",
              " 'a',\n",
              " 'doubt',\n",
              " 'after',\n",
              " 'the',\n",
              " 'session',\n",
              " '?',\n",
              " 'you',\n",
              " 'will',\n",
              " 'have',\n",
              " 'to',\n",
              " 'fill',\n",
              " 'a',\n",
              " 'google',\n",
              " 'form',\n",
              " 'provided',\n",
              " 'in',\n",
              " 'your',\n",
              " 'dashboard',\n",
              " 'and',\n",
              " 'our',\n",
              " 'team',\n",
              " 'will',\n",
              " 'contact',\n",
              " 'you',\n",
              " 'for',\n",
              " 'a',\n",
              " '1',\n",
              " 'on',\n",
              " '1',\n",
              " 'doubt',\n",
              " 'clearance',\n",
              " 'session',\n",
              " 'if',\n",
              " 'i',\n",
              " 'join',\n",
              " 'the',\n",
              " 'program',\n",
              " 'late',\n",
              " ',',\n",
              " 'can',\n",
              " 'i',\n",
              " 'still',\n",
              " 'ask',\n",
              " 'past',\n",
              " 'week',\n",
              " 'doubts',\n",
              " '?',\n",
              " 'yes',\n",
              " ',',\n",
              " 'just',\n",
              " 'select',\n",
              " 'past',\n",
              " 'week',\n",
              " 'doubt',\n",
              " 'in',\n",
              " 'the',\n",
              " 'doubt',\n",
              " 'clearance',\n",
              " 'google',\n",
              " 'form',\n",
              " '.',\n",
              " 'i',\n",
              " 'am',\n",
              " 'living',\n",
              " 'outside',\n",
              " 'india',\n",
              " 'and',\n",
              " 'i',\n",
              " 'am',\n",
              " 'not',\n",
              " 'able',\n",
              " 'to',\n",
              " 'make',\n",
              " 'the',\n",
              " 'payment',\n",
              " 'on',\n",
              " 'the',\n",
              " 'website',\n",
              " ',',\n",
              " 'what',\n",
              " 'should',\n",
              " 'i',\n",
              " 'do',\n",
              " '?',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'contact',\n",
              " 'us',\n",
              " 'by',\n",
              " 'sending',\n",
              " 'a',\n",
              " 'mail',\n",
              " 'at',\n",
              " 'nitish.campusx',\n",
              " '@',\n",
              " 'gmai.com',\n",
              " 'certificate',\n",
              " 'and',\n",
              " 'placement',\n",
              " 'assistance',\n",
              " 'related',\n",
              " 'queries',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'criteria',\n",
              " 'to',\n",
              " 'get',\n",
              " 'the',\n",
              " 'certificate',\n",
              " '?',\n",
              " 'there',\n",
              " 'are',\n",
              " '2',\n",
              " 'criterias',\n",
              " ':',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'fee',\n",
              " 'of',\n",
              " 'rs',\n",
              " '5600',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'attempt',\n",
              " 'all',\n",
              " 'the',\n",
              " 'course',\n",
              " 'assessments',\n",
              " '.',\n",
              " 'i',\n",
              " 'am',\n",
              " 'joining',\n",
              " 'late',\n",
              " '.',\n",
              " 'how',\n",
              " 'can',\n",
              " 'i',\n",
              " 'pay',\n",
              " 'payment',\n",
              " 'of',\n",
              " 'the',\n",
              " 'earlier',\n",
              " 'months',\n",
              " '?',\n",
              " 'you',\n",
              " 'will',\n",
              " 'get',\n",
              " 'a',\n",
              " 'link',\n",
              " 'to',\n",
              " 'pay',\n",
              " 'fee',\n",
              " 'of',\n",
              " 'earlier',\n",
              " 'months',\n",
              " 'in',\n",
              " 'your',\n",
              " 'dashboard',\n",
              " 'once',\n",
              " 'you',\n",
              " 'pay',\n",
              " 'for',\n",
              " 'the',\n",
              " 'current',\n",
              " 'month',\n",
              " '.',\n",
              " 'i',\n",
              " 'have',\n",
              " 'read',\n",
              " 'that',\n",
              " 'placement',\n",
              " 'assistance',\n",
              " 'is',\n",
              " 'a',\n",
              " 'part',\n",
              " 'of',\n",
              " 'this',\n",
              " 'program',\n",
              " '.',\n",
              " 'what',\n",
              " 'comes',\n",
              " 'under',\n",
              " 'placement',\n",
              " 'assistance',\n",
              " '?',\n",
              " 'this',\n",
              " 'is',\n",
              " 'to',\n",
              " 'clarify',\n",
              " 'that',\n",
              " 'placement',\n",
              " 'assistance',\n",
              " 'does',\n",
              " 'not',\n",
              " 'mean',\n",
              " 'placement',\n",
              " 'guarantee',\n",
              " '.',\n",
              " 'so',\n",
              " 'we',\n",
              " 'dont',\n",
              " 'guarantee',\n",
              " 'you',\n",
              " 'any',\n",
              " 'jobs',\n",
              " 'or',\n",
              " 'for',\n",
              " 'that',\n",
              " 'matter',\n",
              " 'even',\n",
              " 'interview',\n",
              " 'calls',\n",
              " '.',\n",
              " 'so',\n",
              " 'if',\n",
              " 'you',\n",
              " 'are',\n",
              " 'planning',\n",
              " 'to',\n",
              " 'join',\n",
              " 'this',\n",
              " 'course',\n",
              " 'just',\n",
              " 'for',\n",
              " 'placements',\n",
              " ',',\n",
              " 'i',\n",
              " 'am',\n",
              " 'afraid',\n",
              " 'you',\n",
              " 'will',\n",
              " 'be',\n",
              " 'disappointed',\n",
              " '.',\n",
              " 'here',\n",
              " 'is',\n",
              " 'what',\n",
              " 'comes',\n",
              " ...]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_tokens = word_tokenize(document.lower())\n",
        "print(\"Token length:\", len(all_tokens))\n",
        "all_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30GxEjgzcfY",
        "outputId": "63c6bf46-c4de-4126-8c12-5f574f70a545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab length: 289\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'about': 1,\n",
              " 'the': 2,\n",
              " 'program': 3,\n",
              " 'what': 4,\n",
              " 'is': 5,\n",
              " 'course': 6,\n",
              " 'fee': 7,\n",
              " 'for': 8,\n",
              " 'data': 9,\n",
              " 'science': 10,\n",
              " 'mentorship': 11,\n",
              " '(': 12,\n",
              " 'dsmp': 13,\n",
              " '2023': 14,\n",
              " ')': 15,\n",
              " 'follows': 16,\n",
              " 'a': 17,\n",
              " 'monthly': 18,\n",
              " 'subscription': 19,\n",
              " 'model': 20,\n",
              " 'where': 21,\n",
              " 'you': 22,\n",
              " 'have': 23,\n",
              " 'to': 24,\n",
              " 'make': 25,\n",
              " 'payments': 26,\n",
              " 'of': 27,\n",
              " 'rs': 28,\n",
              " '799/month': 29,\n",
              " '.': 30,\n",
              " 'total': 31,\n",
              " 'duration': 32,\n",
              " '?': 33,\n",
              " '7': 34,\n",
              " 'months': 35,\n",
              " 'so': 36,\n",
              " 'becomes': 37,\n",
              " '799': 38,\n",
              " '*': 39,\n",
              " '=': 40,\n",
              " '5600': 41,\n",
              " 'approx': 42,\n",
              " 'syllabus': 43,\n",
              " 'we': 44,\n",
              " 'will': 45,\n",
              " 'be': 46,\n",
              " 'covering': 47,\n",
              " 'following': 48,\n",
              " 'modules': 49,\n",
              " ':': 50,\n",
              " 'python': 51,\n",
              " 'fundamentals': 52,\n",
              " 'libraries': 53,\n",
              " 'analysis': 54,\n",
              " 'sql': 55,\n",
              " 'maths': 56,\n",
              " 'machine': 57,\n",
              " 'learning': 58,\n",
              " 'ml': 59,\n",
              " 'algorithms': 60,\n",
              " 'practical': 61,\n",
              " 'mlops': 62,\n",
              " 'case': 63,\n",
              " 'studies': 64,\n",
              " 'can': 65,\n",
              " 'check': 66,\n",
              " 'detailed': 67,\n",
              " 'here': 68,\n",
              " '-': 69,\n",
              " 'https': 70,\n",
              " '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390': 71,\n",
              " 'deep': 72,\n",
              " 'and': 73,\n",
              " 'nlp': 74,\n",
              " 'part': 75,\n",
              " 'this': 76,\n",
              " 'no': 77,\n",
              " ',': 78,\n",
              " 'both': 79,\n",
              " 'are': 80,\n",
              " 'not': 81,\n",
              " 'â€™': 82,\n",
              " 's': 83,\n",
              " 'curriculum': 84,\n",
              " 'if': 85,\n",
              " 'i': 86,\n",
              " 'miss': 87,\n",
              " 'live': 88,\n",
              " 'session': 89,\n",
              " 'get': 90,\n",
              " 'recording': 91,\n",
              " 'yes': 92,\n",
              " 'all': 93,\n",
              " 'our': 94,\n",
              " 'sessions': 95,\n",
              " 'recorded': 96,\n",
              " 'even': 97,\n",
              " 'go': 98,\n",
              " 'back': 99,\n",
              " 'watch': 100,\n",
              " 'find': 101,\n",
              " 'class': 102,\n",
              " 'schedule': 103,\n",
              " 'checkout': 104,\n",
              " 'google': 105,\n",
              " 'sheet': 106,\n",
              " 'see': 107,\n",
              " 'month': 108,\n",
              " 'by': 109,\n",
              " 'time': 110,\n",
              " 'table': 111,\n",
              " '//docs.google.com/spreadsheets/d/16ootax_a6oraecg4emgexhqqpv3noqpyku7rj6arozk/edit': 112,\n",
              " 'usp=sharing': 113,\n",
              " 'roughly': 114,\n",
              " 'last': 115,\n",
              " '2': 116,\n",
              " 'hours': 117,\n",
              " 'language': 118,\n",
              " 'spoken': 119,\n",
              " 'instructor': 120,\n",
              " 'during': 121,\n",
              " 'hinglish': 122,\n",
              " 'how': 123,\n",
              " 'informed': 124,\n",
              " 'upcoming': 125,\n",
              " 'mail': 126,\n",
              " 'from': 127,\n",
              " 'side': 128,\n",
              " 'before': 129,\n",
              " 'every': 130,\n",
              " 'paid': 131,\n",
              " 'once': 132,\n",
              " 'become': 133,\n",
              " 'user': 134,\n",
              " 'do': 135,\n",
              " 'am': 136,\n",
              " 'non-tech': 137,\n",
              " 'background': 138,\n",
              " 'absolutely': 139,\n",
              " 'late': 140,\n",
              " 'join': 141,\n",
              " 'in': 142,\n",
              " 'middle': 143,\n",
              " 'anytime': 144,\n",
              " 'join/pay': 145,\n",
              " 'able': 146,\n",
              " 'past': 147,\n",
              " 'lectures': 148,\n",
              " 'payment': 149,\n",
              " 'content': 150,\n",
              " 'your': 151,\n",
              " 'dashboard': 152,\n",
              " 'submit': 153,\n",
              " 'task': 154,\n",
              " 'don': 155,\n",
              " 't': 156,\n",
              " 'provide': 157,\n",
              " 'with': 158,\n",
              " 'solutions': 159,\n",
              " 'self': 160,\n",
              " 'evaluate': 161,\n",
              " 'yourself': 162,\n",
              " 'contact': 163,\n",
              " 'us': 164,\n",
              " 'at': 165,\n",
              " 'nitish.campusx': 166,\n",
              " '@': 167,\n",
              " 'gmail.com': 168,\n",
              " 'payment/registration': 169,\n",
              " 'related': 170,\n",
              " 'questions': 171,\n",
              " 'youtube': 172,\n",
              " 'channel': 173,\n",
              " 'or': 174,\n",
              " 'website': 175,\n",
              " 'on': 176,\n",
              " 'link': 177,\n",
              " '//learnwith.campusx.in/': 178,\n",
              " 'pay': 179,\n",
              " 'entire': 180,\n",
              " 'amount': 181,\n",
              " 'unfortunately': 182,\n",
              " 'validity': 183,\n",
              " 'suppose': 184,\n",
              " '15th': 185,\n",
              " 'jan': 186,\n",
              " 'then': 187,\n",
              " 'again': 188,\n",
              " '1st': 189,\n",
              " 'feb': 190,\n",
              " 'feb.': 191,\n",
              " 'period': 192,\n",
              " '30': 193,\n",
              " 'days': 194,\n",
              " 'day': 195,\n",
              " 'essentially': 196,\n",
              " 'wait': 197,\n",
              " 'end': 198,\n",
              " 'like': 199,\n",
              " 'after': 200,\n",
              " 'making': 201,\n",
              " 'refund': 202,\n",
              " 'policy': 203,\n",
              " 'made': 204,\n",
              " 'living': 205,\n",
              " 'outside': 206,\n",
              " 'india': 207,\n",
              " 'should': 208,\n",
              " 'sending': 209,\n",
              " 'post': 210,\n",
              " 'registration': 211,\n",
              " 'queries': 212,\n",
              " 'till': 213,\n",
              " 'when': 214,\n",
              " 'view': 215,\n",
              " 'videos': 216,\n",
              " 'one': 217,\n",
              " 'tricky': 218,\n",
              " 'read': 219,\n",
              " 'carefully': 220,\n",
              " 'valid': 221,\n",
              " 'purchased': 222,\n",
              " '21st': 223,\n",
              " '20th': 224,\n",
              " 'but': 225,\n",
              " 'purchase': 226,\n",
              " 'over': 227,\n",
              " 'installments': 228,\n",
              " 'aug': 229,\n",
              " '2024.': 230,\n",
              " 'why': 231,\n",
              " 'lifetime': 232,\n",
              " 'provided': 233,\n",
              " 'because': 234,\n",
              " 'low': 235,\n",
              " 'reach': 236,\n",
              " 'out': 237,\n",
              " 'doubt': 238,\n",
              " 'fill': 239,\n",
              " 'form': 240,\n",
              " 'team': 241,\n",
              " '1': 242,\n",
              " 'clearance': 243,\n",
              " 'still': 244,\n",
              " 'ask': 245,\n",
              " 'week': 246,\n",
              " 'doubts': 247,\n",
              " 'just': 248,\n",
              " 'select': 249,\n",
              " 'gmai.com': 250,\n",
              " 'certificate': 251,\n",
              " 'placement': 252,\n",
              " 'assistance': 253,\n",
              " 'criteria': 254,\n",
              " 'there': 255,\n",
              " 'criterias': 256,\n",
              " 'attempt': 257,\n",
              " 'assessments': 258,\n",
              " 'joining': 259,\n",
              " 'earlier': 260,\n",
              " 'current': 261,\n",
              " 'that': 262,\n",
              " 'comes': 263,\n",
              " 'under': 264,\n",
              " 'clarify': 265,\n",
              " 'does': 266,\n",
              " 'mean': 267,\n",
              " 'guarantee': 268,\n",
              " 'dont': 269,\n",
              " 'any': 270,\n",
              " 'jobs': 271,\n",
              " 'matter': 272,\n",
              " 'interview': 273,\n",
              " 'calls': 274,\n",
              " 'planning': 275,\n",
              " 'placements': 276,\n",
              " 'afraid': 277,\n",
              " 'disappointed': 278,\n",
              " 'portfolio': 279,\n",
              " 'building': 280,\n",
              " 'soft': 281,\n",
              " 'skill': 282,\n",
              " 'industry': 283,\n",
              " 'mentors': 284,\n",
              " 'discussion': 285,\n",
              " 'job': 286,\n",
              " 'hunting': 287,\n",
              " 'strategies': 288}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = {'<unk>': 0}\n",
        "\n",
        "for token in Counter(all_tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "print(\"vocab length:\", len(vocab))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x52A3E1K1zjn"
      },
      "outputs": [],
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "  numerical_sentence = []\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "  return numerical_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eu66Zo3e1Wh9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numerical_sentences length: 78\n"
          ]
        }
      ],
      "source": [
        "input_sentences = document.split('\\n')\n",
        "numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  tokens = word_tokenize(sentence.lower())\n",
        "  numerical_sentences.append(text_to_indices(tokens, vocab))\n",
        "\n",
        "print(\"numerical_sentences length:\", len(numerical_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Training Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "80rIx4aq6ele"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training_sequence count: 942\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [4, 5], [4, 5, 2], [4, 5, 2, 6]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_sequence = []\n",
        "for sentence in numerical_sentences:\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])\n",
        "    \n",
        "print(\"training_sequence count:\", len(training_sequence))\n",
        "training_sequence[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padding Training Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z_fiVZ8GRo",
        "outputId": "dc0971ee-ecb8-4061-c6aa-c5d751bb1da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max sequence length: 62\n"
          ]
        }
      ],
      "source": [
        "all_seq_lengths = []\n",
        "for sequence in training_sequence:\n",
        "  all_seq_lengths.append(len(sequence))\n",
        "\n",
        "max_seq_length = max(all_seq_lengths)\n",
        "print(\"max sequence length:\", max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dtPg5uRN9Cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "padded_training_sequence length: 62\n"
          ]
        }
      ],
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "  padding_length = max_seq_length - len(sequence)\n",
        "  padded_training_sequence.append([0]*padding_length + sequence)\n",
        "  \n",
        "print(\"padded_training_sequence length:\", len(padded_training_sequence[10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split the Features and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "padded_training_sequence shape: torch.Size([942, 62])\n",
            "X shape: torch.Size([942, 61])\n",
            "y shape: torch.Size([942])\n"
          ]
        }
      ],
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)\n",
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]\n",
        "\n",
        "print(\"padded_training_sequence shape:\", padded_training_sequence.shape)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   0,   4,   5],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287],\n",
              "        [  0,   0,   0,  ..., 286, 287, 288]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_training_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ed_PLHJ-Dgv",
        "outputId": "7095458b-a2e8-4dc7-f150-80fd56d2c281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 285, 176],\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eReVrcX9-EUU",
        "outputId": "f2cca2e3-da31-4ef5-bc13-593203462048"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  2,   3,   5,   2,   6,   7,   8,   9,  10,  11,   3,  12,  13,  14,\n",
              "         15,   6,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  18,  26,\n",
              "         27,  28,  29,  30,   5,   2,  31,  32,  27,   2,   6,  33,  31,  32,\n",
              "         27,   2,   6,   5,  34,  35,  30,  36,   2,  31,   6,   7,  37,  38,\n",
              "         39,  34,  40,  28,  41,  12,  42,  30,  15,   5,   2,  43,  27,   2,\n",
              "         11,   3,  33,  45,  46,  47,   2,  48,  49,  50,  52,  53,   8,   9,\n",
              "         10,  54,   8,   9,  10,   8,  57,  58,  60,  59,  64,  65,  66,   2,\n",
              "         67,  43,  68,  69,  70,  50,  71,  72,  58,  73,  74,  46,  17,  75,\n",
              "         27,  76,   3,  33,  78,  74,  73,  72,  58,  79,  80,  81,  17,  75,\n",
              "         27,  76,   3,  82,  83,  84,  30,  85,  86,  87,  17,  88,  89,  33,\n",
              "         45,  86,  90,  17,  91,  27,   2,  89,  33,  93,  94,  95,  80,  96,\n",
              "         78,  36,  97,  85,  22,  87,  17,  89,  22,  65,  98,  99,  73, 100,\n",
              "          2,  91,  30,  65,  86, 101,   2, 102, 103,  33,  76, 105, 106,  24,\n",
              "        107, 108, 109, 108, 110, 111,  27,   2,   6,  69,  70,  50, 112,  33,\n",
              "        113,  30,   5,   2, 110,  32,  27,  93,   2,  88,  95,  33,  78,  93,\n",
              "          2,  95, 115, 116, 117,  30,   5,   2, 118, 119, 109,   2, 120, 121,\n",
              "          2,  95,  33,  45,  86,  46, 124,   1,   2, 125, 102,  33,  45,  90,\n",
              "         17, 126, 127,  94, 128, 129, 130, 131,  89, 132,  22, 133,  17, 131,\n",
              "        134,  30,  86, 135,  76,   6,  85,  86, 136, 127,  17, 137, 138,  33,\n",
              "         78, 139,  30, 136, 140,  78,  65,  86, 141,   2,   3, 142,   2, 143,\n",
              "         33,  78,  22,  65, 141,   2,   3, 144,  30,  86, 145, 142,   2, 143,\n",
              "         78,  45,  86,  46, 146,  24, 107,  93,   2, 147, 148,  33,  78, 132,\n",
              "         22,  25,   2, 149,  22,  45,  46, 146,  24, 107,  93,   2, 147, 150,\n",
              "        142, 151, 152,  30, 135,  86,  23,  24, 153,   2, 154,  33, 155,  82,\n",
              "        156,  23,  24, 153,   2, 154,  30,  44,  45, 157,  22, 158,   2, 159,\n",
              "         78,  22,  23,  24, 160, 161,   2, 154, 162,  30,  44, 135,  63,  64,\n",
              "        142,   2,   3,  33,  30,  65,  44, 163,  22,  33,  65, 126, 164, 165,\n",
              "        166, 167, 168, 170, 171, 135,  44,  23,  24,  25,  94,  26,  33, 151,\n",
              "        172, 173, 174, 175,  33,  23,  24,  25,  93, 151,  18,  26, 176,  94,\n",
              "        175,  30,  68,   5,   2, 177,   8,  94, 175,  69,  70,  50, 178,  44,\n",
              "        179,   2, 180, 181,  27,  28,  41,  93, 165, 132,  33,  77,  78,   2,\n",
              "          3,  16,  17,  18,  19,  20,  30,   5,   2, 183,  27,  18,  19,  33,\n",
              "        184,  85,  86, 179, 176, 185, 186,  78, 187, 135,  86,  23,  24, 179,\n",
              "        188, 176, 189, 190, 174, 185, 190, 191,   2, 183, 192,   5, 193, 194,\n",
              "        127,   2, 195,  22,  25,   2, 149,  30,  36, 196,  22,  65, 141, 144,\n",
              "         22, 155,  82, 156,  23,  24, 197,   8,  17, 108,  24, 198,  30,  85,\n",
              "         86, 155,  82, 156, 199,   2,   6, 200, 201,   2, 149,  30,   4,   5,\n",
              "          2, 202, 203,  33,  90,  17,  34, 194, 202, 192, 127,   2, 195,  22,\n",
              "         23, 204,   2, 149,  30, 136, 205, 206, 207,  73,  86, 136,  81, 146,\n",
              "         24,  25,   2, 149, 176,   2, 175,  78,   4, 208,  86, 135,  33,  23,\n",
              "         24, 163, 164, 109, 209,  17, 126, 165, 166, 167, 168, 211, 212, 214,\n",
              "         65,  86, 215,   2, 131, 216, 176,   2, 175,  33, 217,   5, 218,  78,\n",
              "         36, 219, 220,  30,  22,  65, 100,   2, 216, 213, 151,  19,   5, 221,\n",
              "         30, 184,  22,  23, 222,  19, 176, 223, 186,  78,  22,  45,  46, 146,\n",
              "         24, 100,  93,   2, 147, 131,  95, 142,   2, 192,  27, 223, 186,  24,\n",
              "        224, 191, 225, 200, 223, 190,  22,  45,  23,  24, 226,   2,  19, 188,\n",
              "         30, 132,   2,   6,   5, 227,  73,  22,  23, 131, 164,  28,  41,  12,\n",
              "        174,  34, 228,  27,  28,  38,  15,  22,  45,  46, 146,  24, 100,   2,\n",
              "        131,  95, 213, 229,   0,  30, 232, 183,   5,  81, 233,  33,  27,   2,\n",
              "        235,   6,   7,  30,  65,  86, 236, 237, 142,  63,  27,  17, 238, 200,\n",
              "          2,  89,  33,  45,  23,  24, 239,  17, 105, 240, 233, 142, 151, 152,\n",
              "         73,  94, 241,  45, 163,  22,   8,  17, 242, 176, 242, 238, 243,  89,\n",
              "         86, 141,   2,   3, 140,  78,  65,  86, 244, 245, 147, 246, 247,  33,\n",
              "         78, 248, 249, 147, 246, 238, 142,   2, 238, 243, 105, 240,  30, 136,\n",
              "        205, 206, 207,  73,  86, 136,  81, 146,  24,  25,   2, 149, 176,   2,\n",
              "        175,  78,   4, 208,  86, 135,  33,  23,  24, 163, 164, 109, 209,  17,\n",
              "        126, 165, 166, 167, 250,  73, 252, 253, 170, 212,   5,   2, 254,  24,\n",
              "         90,   2, 251,  33,  80, 116, 256,  50,  23,  24, 179,   2, 180,   7,\n",
              "         27,  28,  41,  23,  24, 257,  93,   2,   6, 258,  30, 136, 259, 140,\n",
              "         30, 123,  65,  86, 179, 149,  27,   2, 260,  35,  33,  45,  90,  17,\n",
              "        177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,  22, 179,   8,\n",
              "          2, 261, 108,  30,  23, 219, 262, 252, 253,   5,  17,  75,  27,  76,\n",
              "          3,  30,   4, 263, 264, 252, 253,  33,   5,  24, 265, 262, 252, 253,\n",
              "        266,  81, 267, 252, 268,  30,  36,  44, 269, 268,  22, 270, 271, 174,\n",
              "          8, 262, 272,  97, 273, 274,  30,  36,  85,  22,  80, 275,  24, 141,\n",
              "         76,   6, 248,   8, 276,  78,  86, 136, 277,  22,  45,  46, 278,  30,\n",
              "         68,   5,   4, 263, 264, 252, 253, 280,  95, 282,  95, 158, 283, 284,\n",
              "        176, 286, 287, 288])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X.to(device)\n",
        "    self.y = y.to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "outputs": [],
      "source": [
        "dataset = MyDataset(X, y)\n",
        "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Design the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    logits = self.fc(final_hidden_state.squeeze(0))\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_sequence: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "input_sequence shape\t: torch.Size([1, 61])\n",
            "emb_output shape\t: torch.Size([1, 61, 100])\n",
            "lstm_hidden_states shape\t: torch.Size([1, 61, 150])\n",
            "lstm_final_hidden_state shape\t: torch.Size([1, 1, 150])\n",
            "lstm_final_cell_state shape\t: torch.Size([1, 1, 150])\n",
            "fc_output shape\t\t: torch.Size([1, 289])\n"
          ]
        }
      ],
      "source": [
        "# Test the layers\n",
        "emb_layer = nn.Embedding(289, embedding_dim=100)\n",
        "lstm_layer = nn.LSTM(100, 150, batch_first=True)\n",
        "fc_layer = nn.Linear(150, 289)\n",
        "\n",
        "input_sequence = dataset[0][0].reshape(1,-1).to('cpu')\n",
        "print(\"input_sequence:\", input_sequence)\n",
        "print(\"input_sequence shape\\t:\", input_sequence.shape)\n",
        "\n",
        "emb_layer_output = emb_layer(input_sequence)\n",
        "print(\"emb_output shape\\t:\", emb_layer_output.shape)\n",
        "\n",
        "hidden_states, (final_hidden_state, final_cell_state)= lstm_layer(emb_layer_output)\n",
        "print(\"lstm_hidden_states shape\\t:\", hidden_states.shape)\n",
        "print(\"lstm_final_hidden_state shape\\t:\", final_hidden_state.shape)\n",
        "print(\"lstm_final_cell_state shape\\t:\", final_cell_state.shape)\n",
        "\n",
        "fc_layer_output = fc_layer(final_hidden_state.squeeze(0))\n",
        "print(\"fc_output shape\\t\\t:\", fc_layer_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(289, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=289, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = LSTM(len(vocab)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "7bc238c9-56d3-4558-db07-41d2474aa64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " -> batch 001 | loss: 5.70\n",
            " -> batch 009 | loss: 5.65\n",
            " -> batch 017 | loss: 5.63\n",
            " -> batch 025 | loss: 5.52\n",
            "Epoch: 001/050 | epoch_loss: 166.40\n",
            " -> batch 001 | loss: 5.10\n",
            " -> batch 009 | loss: 4.93\n",
            " -> batch 017 | loss: 4.77\n",
            " -> batch 025 | loss: 5.01\n",
            "Epoch: 002/050 | epoch_loss: 147.15\n",
            " -> batch 001 | loss: 4.79\n",
            " -> batch 009 | loss: 4.62\n",
            " -> batch 017 | loss: 4.21\n",
            " -> batch 025 | loss: 4.47\n",
            "Epoch: 003/050 | epoch_loss: 134.64\n",
            " -> batch 001 | loss: 4.00\n",
            " -> batch 009 | loss: 4.06\n",
            " -> batch 017 | loss: 3.69\n",
            " -> batch 025 | loss: 4.10\n",
            "Epoch: 004/050 | epoch_loss: 122.12\n",
            " -> batch 001 | loss: 3.64\n",
            " -> batch 009 | loss: 3.94\n",
            " -> batch 017 | loss: 3.95\n",
            " -> batch 025 | loss: 3.57\n",
            "Epoch: 005/050 | epoch_loss: 110.37\n",
            " -> batch 001 | loss: 3.62\n",
            " -> batch 009 | loss: 3.20\n",
            " -> batch 017 | loss: 3.77\n",
            " -> batch 025 | loss: 2.89\n",
            "Epoch: 006/050 | epoch_loss: 99.04\n",
            " -> batch 001 | loss: 3.15\n",
            " -> batch 009 | loss: 2.74\n",
            " -> batch 017 | loss: 2.99\n",
            " -> batch 025 | loss: 2.80\n",
            "Epoch: 007/050 | epoch_loss: 88.17\n",
            " -> batch 001 | loss: 2.61\n",
            " -> batch 009 | loss: 2.28\n",
            " -> batch 017 | loss: 2.82\n",
            " -> batch 025 | loss: 2.83\n",
            "Epoch: 008/050 | epoch_loss: 78.31\n",
            " -> batch 001 | loss: 2.04\n",
            " -> batch 009 | loss: 2.49\n",
            " -> batch 017 | loss: 2.06\n",
            " -> batch 025 | loss: 2.63\n",
            "Epoch: 009/050 | epoch_loss: 69.52\n",
            " -> batch 001 | loss: 2.19\n",
            " -> batch 009 | loss: 2.04\n",
            " -> batch 017 | loss: 1.85\n",
            " -> batch 025 | loss: 2.23\n",
            "Epoch: 010/050 | epoch_loss: 60.89\n",
            " -> batch 001 | loss: 1.92\n",
            " -> batch 009 | loss: 1.69\n",
            " -> batch 017 | loss: 1.84\n",
            " -> batch 025 | loss: 1.68\n",
            "Epoch: 011/050 | epoch_loss: 53.83\n",
            " -> batch 001 | loss: 1.62\n",
            " -> batch 009 | loss: 1.25\n",
            " -> batch 017 | loss: 1.58\n",
            " -> batch 025 | loss: 1.53\n",
            "Epoch: 012/050 | epoch_loss: 47.65\n",
            " -> batch 001 | loss: 1.25\n",
            " -> batch 009 | loss: 1.23\n",
            " -> batch 017 | loss: 1.53\n",
            " -> batch 025 | loss: 1.22\n",
            "Epoch: 013/050 | epoch_loss: 41.15\n",
            " -> batch 001 | loss: 1.23\n",
            " -> batch 009 | loss: 1.03\n",
            " -> batch 017 | loss: 1.28\n",
            " -> batch 025 | loss: 1.02\n",
            "Epoch: 014/050 | epoch_loss: 36.38\n",
            " -> batch 001 | loss: 1.02\n",
            " -> batch 009 | loss: 0.97\n",
            " -> batch 017 | loss: 1.24\n",
            " -> batch 025 | loss: 1.00\n",
            "Epoch: 015/050 | epoch_loss: 31.97\n",
            " -> batch 001 | loss: 0.95\n",
            " -> batch 009 | loss: 0.87\n",
            " -> batch 017 | loss: 0.89\n",
            " -> batch 025 | loss: 1.08\n",
            "Epoch: 016/050 | epoch_loss: 27.88\n",
            " -> batch 001 | loss: 0.76\n",
            " -> batch 009 | loss: 0.72\n",
            " -> batch 017 | loss: 0.68\n",
            " -> batch 025 | loss: 0.76\n",
            "Epoch: 017/050 | epoch_loss: 24.95\n",
            " -> batch 001 | loss: 0.71\n",
            " -> batch 009 | loss: 0.74\n",
            " -> batch 017 | loss: 0.58\n",
            " -> batch 025 | loss: 0.70\n",
            "Epoch: 018/050 | epoch_loss: 22.00\n",
            " -> batch 001 | loss: 0.59\n",
            " -> batch 009 | loss: 0.60\n",
            " -> batch 017 | loss: 0.67\n",
            " -> batch 025 | loss: 0.76\n",
            "Epoch: 019/050 | epoch_loss: 19.74\n",
            " -> batch 001 | loss: 0.66\n",
            " -> batch 009 | loss: 0.47\n",
            " -> batch 017 | loss: 0.60\n",
            " -> batch 025 | loss: 0.74\n",
            "Epoch: 020/050 | epoch_loss: 17.42\n",
            " -> batch 001 | loss: 0.53\n",
            " -> batch 009 | loss: 0.50\n",
            " -> batch 017 | loss: 0.47\n",
            " -> batch 025 | loss: 0.76\n",
            "Epoch: 021/050 | epoch_loss: 16.04\n",
            " -> batch 001 | loss: 0.52\n",
            " -> batch 009 | loss: 0.50\n",
            " -> batch 017 | loss: 0.57\n",
            " -> batch 025 | loss: 0.57\n",
            "Epoch: 022/050 | epoch_loss: 14.47\n",
            " -> batch 001 | loss: 0.37\n",
            " -> batch 009 | loss: 0.45\n",
            " -> batch 017 | loss: 0.37\n",
            " -> batch 025 | loss: 0.38\n",
            "Epoch: 023/050 | epoch_loss: 13.04\n",
            " -> batch 001 | loss: 0.35\n",
            " -> batch 009 | loss: 0.39\n",
            " -> batch 017 | loss: 0.44\n",
            " -> batch 025 | loss: 0.43\n",
            "Epoch: 024/050 | epoch_loss: 12.02\n",
            " -> batch 001 | loss: 0.30\n",
            " -> batch 009 | loss: 0.30\n",
            " -> batch 017 | loss: 0.29\n",
            " -> batch 025 | loss: 0.38\n",
            "Epoch: 025/050 | epoch_loss: 11.07\n",
            " -> batch 001 | loss: 0.27\n",
            " -> batch 009 | loss: 0.30\n",
            " -> batch 017 | loss: 0.34\n",
            " -> batch 025 | loss: 0.40\n",
            "Epoch: 026/050 | epoch_loss: 10.22\n",
            " -> batch 001 | loss: 0.31\n",
            " -> batch 009 | loss: 0.26\n",
            " -> batch 017 | loss: 0.40\n",
            " -> batch 025 | loss: 0.33\n",
            "Epoch: 027/050 | epoch_loss: 9.50\n",
            " -> batch 001 | loss: 0.28\n",
            " -> batch 009 | loss: 0.34\n",
            " -> batch 017 | loss: 0.31\n",
            " -> batch 025 | loss: 0.43\n",
            "Epoch: 028/050 | epoch_loss: 8.95\n",
            " -> batch 001 | loss: 0.33\n",
            " -> batch 009 | loss: 0.31\n",
            " -> batch 017 | loss: 0.32\n",
            " -> batch 025 | loss: 0.20\n",
            "Epoch: 029/050 | epoch_loss: 8.55\n",
            " -> batch 001 | loss: 0.43\n",
            " -> batch 009 | loss: 0.32\n",
            " -> batch 017 | loss: 0.24\n",
            " -> batch 025 | loss: 0.34\n",
            "Epoch: 030/050 | epoch_loss: 7.98\n",
            " -> batch 001 | loss: 0.21\n",
            " -> batch 009 | loss: 0.27\n",
            " -> batch 017 | loss: 0.23\n",
            " -> batch 025 | loss: 0.30\n",
            "Epoch: 031/050 | epoch_loss: 7.55\n",
            " -> batch 001 | loss: 0.13\n",
            " -> batch 009 | loss: 0.15\n",
            " -> batch 017 | loss: 0.14\n",
            " -> batch 025 | loss: 0.31\n",
            "Epoch: 032/050 | epoch_loss: 7.19\n",
            " -> batch 001 | loss: 0.15\n",
            " -> batch 009 | loss: 0.20\n",
            " -> batch 017 | loss: 0.28\n",
            " -> batch 025 | loss: 0.36\n",
            "Epoch: 033/050 | epoch_loss: 6.95\n",
            " -> batch 001 | loss: 0.32\n",
            " -> batch 009 | loss: 0.12\n",
            " -> batch 017 | loss: 0.15\n",
            " -> batch 025 | loss: 0.25\n",
            "Epoch: 034/050 | epoch_loss: 6.75\n",
            " -> batch 001 | loss: 0.21\n",
            " -> batch 009 | loss: 0.23\n",
            " -> batch 017 | loss: 0.27\n",
            " -> batch 025 | loss: 0.25\n",
            "Epoch: 035/050 | epoch_loss: 6.31\n",
            " -> batch 001 | loss: 0.23\n",
            " -> batch 009 | loss: 0.19\n",
            " -> batch 017 | loss: 0.29\n",
            " -> batch 025 | loss: 0.23\n",
            "Epoch: 036/050 | epoch_loss: 6.13\n",
            " -> batch 001 | loss: 0.20\n",
            " -> batch 009 | loss: 0.36\n",
            " -> batch 017 | loss: 0.16\n",
            " -> batch 025 | loss: 0.10\n",
            "Epoch: 037/050 | epoch_loss: 6.05\n",
            " -> batch 001 | loss: 0.22\n",
            " -> batch 009 | loss: 0.26\n",
            " -> batch 017 | loss: 0.24\n",
            " -> batch 025 | loss: 0.22\n",
            "Epoch: 038/050 | epoch_loss: 6.01\n",
            " -> batch 001 | loss: 0.22\n",
            " -> batch 009 | loss: 0.25\n",
            " -> batch 017 | loss: 0.16\n",
            " -> batch 025 | loss: 0.27\n",
            "Epoch: 039/050 | epoch_loss: 5.51\n",
            " -> batch 001 | loss: 0.14\n",
            " -> batch 009 | loss: 0.11\n",
            " -> batch 017 | loss: 0.28\n",
            " -> batch 025 | loss: 0.09\n",
            "Epoch: 040/050 | epoch_loss: 5.43\n",
            " -> batch 001 | loss: 0.26\n",
            " -> batch 009 | loss: 0.10\n",
            " -> batch 017 | loss: 0.14\n",
            " -> batch 025 | loss: 0.16\n",
            "Epoch: 041/050 | epoch_loss: 5.23\n",
            " -> batch 001 | loss: 0.18\n",
            " -> batch 009 | loss: 0.11\n",
            " -> batch 017 | loss: 0.12\n",
            " -> batch 025 | loss: 0.10\n",
            "Epoch: 042/050 | epoch_loss: 5.11\n",
            " -> batch 001 | loss: 0.08\n",
            " -> batch 009 | loss: 0.09\n",
            " -> batch 017 | loss: 0.16\n",
            " -> batch 025 | loss: 0.24\n",
            "Epoch: 043/050 | epoch_loss: 4.98\n",
            " -> batch 001 | loss: 0.06\n",
            " -> batch 009 | loss: 0.14\n",
            " -> batch 017 | loss: 0.25\n",
            " -> batch 025 | loss: 0.09\n",
            "Epoch: 044/050 | epoch_loss: 4.90\n",
            " -> batch 001 | loss: 0.07\n",
            " -> batch 009 | loss: 0.21\n",
            " -> batch 017 | loss: 0.21\n",
            " -> batch 025 | loss: 0.23\n",
            "Epoch: 045/050 | epoch_loss: 4.88\n",
            " -> batch 001 | loss: 0.20\n",
            " -> batch 009 | loss: 0.17\n",
            " -> batch 017 | loss: 0.10\n",
            " -> batch 025 | loss: 0.11\n",
            "Epoch: 046/050 | epoch_loss: 4.76\n",
            " -> batch 001 | loss: 0.16\n",
            " -> batch 009 | loss: 0.13\n",
            " -> batch 017 | loss: 0.06\n",
            " -> batch 025 | loss: 0.14\n",
            "Epoch: 047/050 | epoch_loss: 4.63\n",
            " -> batch 001 | loss: 0.07\n",
            " -> batch 009 | loss: 0.12\n",
            " -> batch 017 | loss: 0.29\n",
            " -> batch 025 | loss: 0.20\n",
            "Epoch: 048/050 | epoch_loss: 4.54\n",
            " -> batch 001 | loss: 0.23\n",
            " -> batch 009 | loss: 0.16\n",
            " -> batch 017 | loss: 0.12\n",
            " -> batch 025 | loss: 0.20\n",
            "Epoch: 049/050 | epoch_loss: 4.47\n",
            " -> batch 001 | loss: 0.09\n",
            " -> batch 009 | loss: 0.32\n",
            " -> batch 017 | loss: 0.12\n",
            " -> batch 025 | loss: 0.20\n",
            "Epoch: 050/050 | epoch_loss: 4.36\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  model = model.train()  \n",
        "  for batch_idx, (batch_x, batch_y) in enumerate(train_dataloader):\n",
        "    # forward pass\n",
        "    logits = model(batch_x)\n",
        "    loss = criterion(logits, batch_y)\n",
        "    \n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    if not batch_idx % 8:\n",
        "      print(f' -> batch {batch_idx+1:03d} | loss: {loss:.2f}')\n",
        "  \n",
        "  print(f'Epoch: {epoch+1:03d}/{epochs:03d} | epoch_loss: {epoch_loss:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "O9f6DkX-ZM-r"
      },
      "outputs": [],
      "source": [
        "def predict(model, vocab, input_text):\n",
        "  tokenized_text = word_tokenize(input_text.lower())\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "  padding_length = max_seq_length - 1 - len(numerical_text)\n",
        "  padded_text = torch.tensor([0]*padding_length + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "  logits = model(padded_text.to(device))\n",
        "  logit, index = torch.max(logits, dim=1)\n",
        "  return list(vocab.keys())[index], logit.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confidence: 9.85\n",
            "Answer: subscription\n"
          ]
        }
      ],
      "source": [
        "prediction, confidence = predict(model, vocab, \"The course follows a monthly\")\n",
        "print(f\"Confidence: {confidence:.2f}\")\n",
        "print(f\"Answer: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "0a36a6da-8118-4989-b754-e69826765f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The course follows a monthly subscription\n",
            "The course follows a monthly subscription model\n",
            "The course follows a monthly subscription model where\n",
            "The course follows a monthly subscription model where you\n",
            "The course follows a monthly subscription model where you have\n",
            "The course follows a monthly subscription model where you have to\n",
            "The course follows a monthly subscription model where you have to make\n",
            "The course follows a monthly subscription model where you have to make monthly\n",
            "The course follows a monthly subscription model where you have to make monthly payments\n",
            "The course follows a monthly subscription model where you have to make monthly payments of\n",
            "The course follows a monthly subscription model where you have to make monthly payments of rs\n",
            "The course follows a monthly subscription model where you have to make monthly payments of rs 799/month\n"
          ]
        }
      ],
      "source": [
        "num_tokens = 12\n",
        "input_prompt = \"The course follows a monthly\"\n",
        "\n",
        "for _ in range(num_tokens):\n",
        "  prediction, logit = predict(model, vocab, input_prompt)  \n",
        "  input_prompt += \" \" + prediction\n",
        "  print(input_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py7o0rJJc5pm",
        "outputId": "d6de41b2-e157-4da6-8dde-cd27de358a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(model, dataloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            probs = model(batch_x)\n",
        "            _, predicted = torch.max(probs, dim=1)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "accuracy = calculate_accuracy(model, test_dataloader)\n",
        "print(f\"Train Accuracy: {accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
